{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #@title Imports. { vertical-output: true }\n",
    "from etils import epath\n",
    "from ml_collections import config_dict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "# from src.perch.inference import colab_utils\n",
    "# colab_utils.initialize(use_tf_gpu=True, disable_warnings=True)\n",
    "\n",
    "from src.perch import audio_utils\n",
    "from src.perch.inference import embed_lib\n",
    "from src.perch.inference import tf_examples\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodule.gadme_datamodule import GADMEDataModule\n",
    "from src.datamodule.base_datamodule import DatasetConfig, LoadersConfig, LoaderConfig\n",
    "from src.datamodule.components.transforms import TransformsWrapper\n",
    "from src.datamodule.components.event_mapping import XCEventMapping\n",
    "from src.datamodule.components.event_decoding import EventDecoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configuration. { vertical-output: true }\n",
    "\n",
    "# Define the model\n",
    "model_choice = 'perch'  #@param\n",
    "model_choice = 'birdnet'  #@param\n",
    "\n",
    "config = config_dict.ConfigDict()\n",
    "config.embed_fn_config = config_dict.ConfigDict()\n",
    "config.embed_fn_config.model_config = config_dict.ConfigDict()\n",
    "\n",
    "# Pick the input and output targets.\n",
    "config.source_file_patterns = ['']  #@param\n",
    "config.output_dir = '/tmp/embeddings'  #@param\n",
    "\n",
    "# For Perch, the directory containing the model.\n",
    "# Alternatively, set the perch_tfhub_model_version, and the model will load\n",
    "# directly from TFHub.\n",
    "# Note that only one of perch_model_path and perch_tfhub_version should be set.\n",
    "perch_model_path = ''  #@param\n",
    "perch_tfhub_version = 2  #@param\n",
    "\n",
    "# For BirdNET, point to the specific tflite file.\n",
    "birdnet_model_path = '/Users/moritzrichert/Downloads/V2.4/BirdNET_GLOBAL_6K_V2.4_Model_FP32.tflite'  #@param\n",
    "if model_choice == 'perch':\n",
    "  config.embed_fn_config.model_key = 'taxonomy_model_tf'\n",
    "  config.embed_fn_config.model_config.window_size_s = 5.0\n",
    "  config.embed_fn_config.model_config.hop_size_s = 5.0\n",
    "  config.embed_fn_config.model_config.sample_rate = 32000\n",
    "  config.embed_fn_config.model_config.tfhub_version = perch_tfhub_version\n",
    "  config.embed_fn_config.model_config.model_path = perch_model_path\n",
    "elif model_choice == 'birdnet':\n",
    "  config.embed_fn_config.model_key = 'birdnet'\n",
    "  config.embed_fn_config.model_config.window_size_s = 3.0\n",
    "  config.embed_fn_config.model_config.hop_size_s = 3.0\n",
    "  config.embed_fn_config.model_config.sample_rate = 48000\n",
    "  config.embed_fn_config.model_config.model_path = birdnet_model_path\n",
    "  # Note: This class list is appropriate for Birdnet 2.1, 2.2, and 2.3\n",
    "  config.embed_fn_config.model_config.class_list_name = 'birdnet_v2_4'\n",
    "  config.embed_fn_config.model_config.num_tflite_threads = 4\n",
    "\n",
    "# Only write embeddings to reduce size.\n",
    "config.embed_fn_config.write_embeddings = True\n",
    "config.embed_fn_config.write_logits = False\n",
    "config.embed_fn_config.write_separated_audio = False\n",
    "config.embed_fn_config.write_raw_audio = False\n",
    "\n",
    "\n",
    "# Embedding windows are broken up into groups, typically one minute in length.\n",
    "# This lets us limit input size to the model, track progres and\n",
    "# recover from failures more easily.\n",
    "config.shard_len_s = 60  #@param\n",
    "config.num_shards_per_file = 10  #@param\n",
    "\n",
    "# Number of parent directories to include in the filename.\n",
    "config.embed_fn_config.file_id_depth = 1\n",
    "\n",
    "# Number of TF Record files to create.\n",
    "config.tf_record_shards = 10  #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading model(s)...\n",
      ".\n",
      "Found 10 source infos.\n",
      "[SourceInfo(filepath='.', id=0, shard_num=0, shard_len_s=60), SourceInfo(filepath='.', id=1, shard_num=1, shard_len_s=60), SourceInfo(filepath='.', id=2, shard_num=2, shard_len_s=60), SourceInfo(filepath='.', id=3, shard_num=3, shard_len_s=60), SourceInfo(filepath='.', id=4, shard_num=4, shard_len_s=60), SourceInfo(filepath='.', id=5, shard_num=5, shard_len_s=60), SourceInfo(filepath='.', id=6, shard_num=6, shard_len_s=60), SourceInfo(filepath='.', id=7, shard_num=7, shard_len_s=60), SourceInfo(filepath='.', id=8, shard_num=8, shard_len_s=60), SourceInfo(filepath='.', id=9, shard_num=9, shard_len_s=60)]\n",
      "/Users/moritzrichert/Projects/GADME-BaselineResults-BA/notebooks/Bird_Embeddings\n",
      "\n",
      "\n",
      "Test-run of model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "#@title Set up. { vertical-output: true }\n",
    "\n",
    "# Set up the embedding function, including loading models.\n",
    "embed_fn = embed_lib.EmbedFn(**config.embed_fn_config)\n",
    "print('\\n\\nLoading model(s)...')\n",
    "embed_fn.setup()\n",
    "\n",
    "# Create output directory and write the configuration.\n",
    "output_dir = epath.Path(config.output_dir)\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "embed_lib.maybe_write_config(config, output_dir)\n",
    "\n",
    "# Create SourceInfos.\n",
    "source_infos = embed_lib.create_source_infos(\n",
    "    config.source_file_patterns,\n",
    "    config.num_shards_per_file,\n",
    "    config.shard_len_s)\n",
    "\n",
    "print(f'Found {len(source_infos)} source infos.')\n",
    "print(source_infos)\n",
    "print(os.getcwd())\n",
    "\n",
    "print('\\n\\nTest-run of model...')\n",
    "window_size_s = config.embed_fn_config.model_config.window_size_s\n",
    "sr = config.embed_fn_config.model_config.sample_rate\n",
    "z = np.zeros([int(sr * window_size_s)])\n",
    "test_embeds = embed_fn.embedding_model.embed(z)\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"DBD-research-group/gadme_v1\"\n",
    "cache_dir = \"/Volumes/BigChongusF/Datasets/Huggingface/gadme_v1/data\"\n",
    "dataset_config = DatasetConfig(cache_dir, \"high_sierras\", dataset_name, \"high_sierras\", 42, 22, 3, 0.2, \"multiclass\")\n",
    "loaders_config = LoadersConfig()\n",
    "loaders_config.train = LoaderConfig(12, True, 6, True, False, True, 2)\n",
    "loaders_config.valid = LoaderConfig(12, False)\n",
    "loaders_config.test = LoaderConfig(12, False)\n",
    "transforms_wrapper = TransformsWrapper(decoding=EventDecoding(0, 10, 48000))\n",
    "# transforms_wrapper = EventDecoding(0, 10, 48000)\n",
    "mapper = XCEventMapping()\n",
    "dm = GADMEDataModule(dataset_config, loaders_config, transforms_wrapper, mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bcb207d230431baa9083f9a65ee501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524b901026a2494183d24d29502a75bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5413 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fab2ee742bf4a6bbf5ce123bc0b4c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm.prepare_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2d75bf8e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = dm.train_dataloader()\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['filepath', 'labels', 'detected_events', 'start_time', 'end_time'],\n",
       "    num_rows: 21650\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[ 0.2774,  0.2697,  0.1854,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0533, -0.0517, -0.0371,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0796,  0.0981,  0.1763,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.1569,  0.0525, -0.0994,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3469, -0.3913, -0.3506,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0100,  0.0033, -0.0137,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " 'labels': tensor([ 0, 14,  0, 18, 15,  0, 21,  7,  0,  0, 16, 14])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dm.train_dataloader()))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27743042, 0.26968205, 0.18535483, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_input = x[\"input_values\"][0].numpy()\n",
    "np_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27743042,  0.26968205,  0.18535483, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05330318, -0.05168802, -0.03712571, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.0796349 ,  0.09809804,  0.1763438 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.15688181,  0.05245745, -0.09936112, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.34689653, -0.39128554, -0.35058004, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00999713,  0.00328362, -0.01369417, ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_batch = x[\"input_values\"].numpy()\n",
    "np_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferenceOutputs(embeddings=array([[[[0.00895297, 1.0881592 , 0.12384493, ..., 0.        ,\n",
       "          0.10322309, 1.4648584 ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.1552803 , 0.18906957, ..., 0.66761416,\n",
       "          0.        , 0.3070067 ]]],\n",
       "\n",
       "\n",
       "       [[[0.06156166, 0.03091764, 0.08061623, ..., 1.2553805 ,\n",
       "          0.11740097, 0.9848521 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.01782457, 0.17104888, ..., 1.3984874 ,\n",
       "          0.        , 1.160324  ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 1.141028  , 0.46233058, ..., 1.0300186 ,\n",
       "          0.05711158, 0.03352364]]],\n",
       "\n",
       "\n",
       "       [[[0.28156266, 0.74211866, 0.02485014, ..., 0.98906773,\n",
       "          0.1429816 , 0.13127708]]]], dtype=float32), logits={'birdnet_v2_4': array([[[[-14.297033 , -13.234331 , -15.535536 , ..., -19.077936 ,\n",
       "          -11.700456 , -14.971894 ]]],\n",
       "\n",
       "\n",
       "       [[[-12.3372345, -16.130344 , -17.099237 , ..., -13.6679945,\n",
       "          -12.124773 , -15.84532  ]]],\n",
       "\n",
       "\n",
       "       [[[-10.2310095, -12.046837 ,  -9.470226 , ..., -10.365631 ,\n",
       "           -8.456606 , -11.36681  ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ -9.964968 , -14.619225 , -12.190367 , ..., -10.552747 ,\n",
       "          -11.19269  , -12.496224 ]]],\n",
       "\n",
       "\n",
       "       [[[-10.766819 , -10.620007 , -13.3616085, ..., -12.130486 ,\n",
       "          -10.086687 ,  -9.236646 ]]],\n",
       "\n",
       "\n",
       "       [[[-15.624904 , -21.144384 , -18.709347 , ..., -17.390493 ,\n",
       "          -16.70024  , -16.436483 ]]]], dtype=float32)}, separated_audio=None, batched=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedds = embed_fn.embedding_model.batch_embed(np_batch)\n",
    "embedds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferenceOutputs(embeddings=array([[[0.00895297, 1.0881592 , 0.12384493, ..., 0.        ,\n",
       "         0.10322309, 1.4648584 ]]], dtype=float32), logits={'birdnet_v2_4': array([[[-14.297033, -13.234331, -15.535536, ..., -19.077936,\n",
       "         -11.700456, -14.971894]]], dtype=float32)}, separated_audio=None, batched=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embed_fn.embedding_model.embed(np_input)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_logits, model_output = embed_fn._audio_to_example_slim(np_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferenceOutputs(embeddings=array([[[0.00895297, 1.0881592 , 0.12384493, ..., 0.        ,\n",
       "         0.10322309, 1.4648584 ]]], dtype=float32), logits={'birdnet_v2_4': array([[[-14.297033, -13.234331, -15.535536, ..., -19.077936,\n",
       "         -11.700456, -14.971894]]], dtype=float32)}, separated_audio=None, batched=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SourceInfo' object has no attribute 'end_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source_info \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(source_infos):\n\u001b[0;32m----> 2\u001b[0m     examples \u001b[38;5;241m=\u001b[39m \u001b[43membed_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_new_SourceInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_info\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/GADME-BaselineResults-BA/src/perch/inference/embed_lib.py:311\u001b[0m, in \u001b[0;36mEmbedFn.process_new_SourceInfo\u001b[0;34m(self, source_info, crop_s)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;129m@beam\u001b[39m\u001b[38;5;241m.\u001b[39mtypehints\u001b[38;5;241m.\u001b[39mwith_output_types(Any)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_new_SourceInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_info:NewSourceInfo, crop_s: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m   window_size_s \u001b[38;5;241m=\u001b[39m \u001b[43msource_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_time\u001b[49m\n\u001b[1;32m    312\u001b[0m   timestamp_offset_s \u001b[38;5;241m=\u001b[39m source_info\u001b[38;5;241m.\u001b[39mstart_time\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m crop_s \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SourceInfo' object has no attribute 'end_time'"
     ]
    }
   ],
   "source": [
    "for source_info in tqdm.tqdm(source_infos):\n",
    "    examples = embed_fn.process_new_SourceInfo(source_info=source_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21650 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Audio loaded successfully.\n",
      "WARNING:absl:The audio at (/Volumes/BigChongusF/Datasets/Huggingface/gadme_v1/data/downloads/extracted/c654a2fa7284c6b9ad2b65fb7d03c399719d51032c53323567e62583eb09dd11/data/xeno-canto/north_america/catharus_guttatus/XC691469.ogg / 0) could not be loaded (audio_too_short). The exception was (no_exception)\n",
      "  0%|          | 1/21650 [00:01<11:40:25,  1.94s/it]WARNING:absl:Audio loaded successfully.\n",
      "  0%|          | 1/21650 [00:18<112:10:42, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Parameter to MergeFrom() must be instance of same class: expected tensorflow.core.example.feature_pb2.Feature got tuple.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf_examples\u001b[38;5;241m.\u001b[39mEmbeddingsTFRecordMultiWriter(\n\u001b[1;32m      3\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir, num_files\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtf_record_shards) \u001b[38;5;28;01mas\u001b[39;00m file_writer:\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m source_info \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(source_infos):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# examples = embed_fn.process(source_info=source_info)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     examples \u001b[38;5;241m=\u001b[39m \u001b[43membed_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_new_SourceInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m examples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m       fail \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Projects/GADME-BaselineResults-BA/src/perch/inference/embed_lib.py:287\u001b[0m, in \u001b[0;36mEmbedFn.process_new_SourceInfo\u001b[0;34m(self, source_info, crop_s)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_s \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    285\u001b[0m   window_size_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_s\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp_offset_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size_s\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/GADME-BaselineResults-BA/src/perch/inference/embed_lib.py:354\u001b[0m, in \u001b[0;36mEmbedFn._process\u001b[0;34m(self, source_info, timestamp_offset_s, window_size_s)\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    351\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...creating embeddings (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, file_id, timestamp_offset_s\n\u001b[1;32m    353\u001b[0m )\n\u001b[0;32m--> 354\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_to_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp_offset_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m beam\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMetrics\u001b[38;5;241m.\u001b[39mcounter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeaminference\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples_processed\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39minc()\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [example]\n",
      "File \u001b[0;32m~/Projects/GADME-BaselineResults-BA/src/perch/inference/embed_lib.py:265\u001b[0m, in \u001b[0;36mEmbedFn.audio_to_example\u001b[0;34m(self, file_id, timestamp_offset_s, audio)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m   write_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_logits\n\u001b[0;32m--> 265\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[43mtf_examples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_outputs_to_tf_example\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_offset_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_offset_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_raw_audio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_raw_audio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_separated_audio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_separated_audio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m example\n",
      "File \u001b[0;32m~/Projects/GADME-BaselineResults-BA/src/perch/inference/tf_examples.py:173\u001b[0m, in \u001b[0;36mmodel_outputs_to_tf_example\u001b[0;34m(model_outputs, file_id, audio, timestamp_offset_s, write_embeddings, write_logits, write_separated_audio, write_raw_audio)\u001b[0m\n\u001b[1;32m    171\u001b[0m   feature[RAW_AUDIO_SHAPE] \u001b[38;5;241m=\u001b[39m int_feature(audio\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(feature))\n\u001b[0;32m--> 173\u001b[0m ex \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mExample(features\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ex\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/5gadme/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:529\u001b[0m, in \u001b[0;36m_AddInitMethod.<locals>.init\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IsMessageMapField(field):\n\u001b[1;32m    528\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m field_value:\n\u001b[0;32m--> 529\u001b[0m     \u001b[43mcopy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMergeFrom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m   copy\u001b[38;5;241m.\u001b[39mupdate(field_value)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/5gadme/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:1311\u001b[0m, in \u001b[0;36m_AddMergeFromMethod.<locals>.MergeFrom\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMergeFrom\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg):\n\u001b[1;32m   1310\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, \u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter to MergeFrom() must be instance of same class: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1313\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (_FullyQualifiedClassName(\u001b[38;5;28mcls\u001b[39m),\n\u001b[1;32m   1314\u001b[0m                                  _FullyQualifiedClassName(msg\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)))\n\u001b[1;32m   1316\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1317\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Modified()\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameter to MergeFrom() must be instance of same class: expected tensorflow.core.example.feature_pb2.Feature got tuple."
     ]
    }
   ],
   "source": [
    "succ, fail = 0,0\n",
    "with tf_examples.EmbeddingsTFRecordMultiWriter(\n",
    "    output_dir=output_dir, num_files=config.tf_record_shards) as file_writer:\n",
    "  for source_info in tqdm.tqdm(source_infos):\n",
    "    # examples = embed_fn.process(source_info=source_info)\n",
    "    examples = embed_fn.process_new_SourceInfo(source_info=source_info)\n",
    "    if examples is None:\n",
    "      fail += 1\n",
    "      continue\n",
    "    for example in examples:\n",
    "      file_writer.write(example.SerializeToString())\n",
    "    succ += 1\n",
    "  file_writer.flush()\n",
    "print(f'\\n\\nSuccessfully processed {succ} source_infos, failed {fail} times.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5gadme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
