# @package _global_
defaults:
  - override /datamodule: WABAD.yaml
  - override /module: multilabel.yaml
  - override /module/network: convnext.yaml
  - override /callbacks: default.yaml
  - override /trainer: single_gpu.yaml
  # - override /datamodule/transforms: bird_default_multilabel.yaml
  - override /paths: default.yaml
  # - override /hydra: default.yaml

tags: ["birdsetLT", "inference"]
seed: 1
train: False
test: True

logger:
  wandb:
    tags: ${tags}
    group: "LT_HSN_convnext"
    mode: disabled
    version: LT_convnext_${seed}_${start_time}

module:

  metrics:
    _target_: uncertainbird.modules.metrics.uncertainty.NoMetricsConfig
    num_labels: 9736  # Set this to the number of classes in BirdSetLT
   

  mask_logits: False
  network:
    model:
      local_checkpoint: null #Add the path to your XCL pretraining checkpoint here, if it is saved locally.
      checkpoint: DBD-research-group/ConvNeXT-Base-BirdSet-XCL #Add the HuggingFace path to your XCL pretraining checkpoint here if it is uploaded on HuggingFace.
      pretrain_info:
        hf_path: ${datamodule.dataset.hf_path}
        hf_name: ${datamodule.dataset.hf_name}
        hf_pretrain_name: XCL
        valid_test_only: False

datamodule:
  dataset:
    dataset_name: ARD
    val_split: null
    class_weights_loss: null
    class_weights_sampler: null
    classlimit: null
    eventlimit: null
    # num_classes: 9736  # Override number of classes to match BirdSetLT
  loaders:
    test:
      batch_size: 2048
      num_workers: 32

callbacks:
  dump_predictions:
    _target_: uncertainbird.callbacks.DumpPredictionsCallback
    save_dir: "${paths.output_dir}/predictions"
    filename_prefix: "masked_test_predictions"
    save_format: "pickle"